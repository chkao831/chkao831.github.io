---
title: "【Fall 2018】Classifying Types of Toxicity in Wikipedia Comments with Natural Language Processing"
excerpt: "Implementatoin of a multi-headed NLP model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models.  <br/><img src='/images/11_toxicity.png'>"
collection: portfolio
---

### This is a final group project of LIGN 167: Deep Learning for Natural Language Understanding at UCSD. 

### [Link to the Project Report.](https://mozilla.github.io/pdf.js/web/viewer.html?file=https://raw.githubusercontent.com/chkao831/FA18_NLP-Classifying-Toxicity-in-Wikipedia-Comments_UCSDLIGN167/master/Project%20Paper.pdf){:target="_blank"}

### [Our project codes are also available on GitHub.](https://github.com/chkao831/FA18_NLP-Classifying-Toxicity-in-Wikipedia-Comments_UCSDLIGN167)

