---
title: "【Fall 2018】Classifying Types of Toxicity in Wikipedia Comments with Natural Language Processing"
excerpt: "Implementatoin of a multi-headed NLP model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models.  <br/><img src='/images/11_toxicity.png'>"
collection: portfolio
---

### This is a final group project of LIGN 167: Deep Learning for Natural Language Understanding at UCSD. 

### [Our project report and codes are available at GitHub.](https://github.com/chkao831/FA18_NLP-Classifying-Toxicity-in-Wikipedia-Comments_UCSDLIGN167)

